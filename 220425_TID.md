# 4월 25일 (월)

## 오늘 한 일

* 융합 프로젝트
  * 01:06
    * 구글맵 크롤링 자세히 누르는 것만 고쳐서 돌리고 얼른 엘라스틱 서치 공부를 해야겠다
    
  * 02:08
  
    * 이게 너무 많으면 append가 안되는 것 같아서 150개까지만 가져오도록 코드를 짜봐야겠다.
  
  * 02:43
  
    * 리뷰 수가 너무 많아서 저장되기 전에 끊기는것 같은데,, 이걸 좀 고쳐봐야겠다.
  
  * 04:01
  
    * 뭐는 올라가고 뭐는 안올라가고 ... 도대체 셀레니움은 왜이러는걸까.
  
  * 09:22
  
    * 우선 코드들을 깃허브에 올리고 상태를 공유했다. 구글맵은 잘 안될 것 같으면 시간 낭비를 하지 않기 위해 건들이지 않기로 했다.
  
      ![image](https://user-images.githubusercontent.com/75322297/165003081-5a579dad-e7fb-4091-be62-70bba45ccb1a.png)
  
  * 09:50
  
    * 엘라스틱 서치 구현 연습
  
  * 09:52
  
    * 엘라스틱 서치란?
      1. 검색에 자주 쓰이는 Apache Lucene Library를 기반으로 만들어진 검색 엔진 어플리케이션
      2. 검색 엔진, 데이터 저장소, 분석 엔진으로 사용될 수 있음
    * ELK 형태란?
      1. Elasticsearch
      2. Logistash
      3. Kibana
  
  * 10:01
  
    * 차근차근 공부할 타이밍이 아니라 빠르게 반영해야하는 특성 상 이론위주보다는 최대한 적용 위주로 생각하면서 접근해야겠다.
    * 참고 블로그 : [https://mixedprograming.tistory.com/11](https://mixedprograming.tistory.com/11)
    * 우선 설치부터 해야한다.
      * 참고 : [https://jjeongil.tistory.com/1521](https://jjeongil.tistory.com/1521)
      * [https://www.elastic.co/kr/downloads/elasticsearch](https://www.elastic.co/kr/downloads/elasticsearch)
  
  * 10:08
  
    * AWS 자바 버전 : `11.0.14.1`
  
  * 10:16
  
    * 환경변수 설정 과정
  
      ![image](https://user-images.githubusercontent.com/75322297/165005640-cac2a343-62bc-4174-bda0-72b3672e3f35.png)
  
      ​			![image](https://user-images.githubusercontent.com/75322297/165005816-680eac9c-4286-46de-b480-6a68426dd095.png)
  
  * 10:27
  
    * 최신 버전 다운
      * `wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.3-linux-x86_64.tar.gz`
  
  * 10:49
  
    * 방화벽 해제
  
      ```
      firewall-cmd --permanent --zone=public --add-port=9200/tcp
      firewall-cmd --reload
      firewall-cmd --list-ports
      ```
  
    * 방화벽 해제시 비밀번호도 쳐줘야한다!
  
  * 10:54
  
    * 엘라스틱 서치 bin폴더로 이동해서 직접 실행
    * ![image](https://user-images.githubusercontent.com/75322297/165008172-06970c73-7a14-4cf0-9891-b5f91d8da3f5.png)
  
  * 10:55
  
    * `curl 패키지 다운`
      * `sudo apt install curl`
    * 엘라스틱서치 확인
      * `curl -XGET localhost:9200`
    * 근데 왜안될까..ㅋㅋㅋ
  
  * 12:53
  
    * 우분투랑 오픈jdk 버전 문제도 있어서 AWS 서버의 18.04에 맞춰서 다시 시도해봐야겠다,...
  
  * 12:59
  
    * 정윤님이 보내주신 코드
  
      ```
      curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
      echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list
      sudo apt update
      sudo apt install elasticsearch
      sudo service elasticsearch start
      ```
  
    * 상태 확인
  
      * `sudo service elasticsearch status`
  
      ![image](https://user-images.githubusercontent.com/75322297/165019066-ab6785ba-4767-4b08-be0f-260fbb637628.png)
  
    * elasticsearch 버전
  
      * `7.17.3`
  
  * 13:10
  
    * 장고와 엘라스틱 서치를 사용한 검색엔진 구축 : [https://blog.nerdfactory.ai/2019/04/29/django-elasticsearch-restframework.html](https://blog.nerdfactory.ai/2019/04/29/django-elasticsearch-restframework.html)
  
  * 13:17
  
    * python3 venv 생성시 에러
  
      ```
      Error: Command '['/home/big/myvenv/bin/python3.7', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.
      ```
  
    * 해당 에러 해결방법
  
      ````
      python3 -m venv (가상환경 이름) --without-pip
      ````
  
    * 가상환경 실행
  
      ```
      source ./(가상환경 이름)/bin/activate
      ```
  
    * pip 설치
  
      ```
      curl https://bootstrap.pypa.io/get-pip.py | python
      ```
  
    * 가상환경 비활성화
  
      ```
      deactivate
      ```
  
  * 13:21
  
    * 참고 : [https://hikwail.tistory.com/33](https://hikwail.tistory.com/33)
    * pip install이 되지 않아 패키지 설치
    * `sudo apt-get install python3-venv python3-pip`
  
  * 14:01
  
    * Python ES API
      * [https://elasticsearch-py.readthedocs.io/en/master/api.html](https://elasticsearch-py.readthedocs.io/en/master/api.html)
  
  * 14:15
  
    * 장고 + 엘라서치 활용 검색프로그램 참고 사이트 : [https://m.blog.naver.com/kyy0810/221494376698](https://m.blog.naver.com/kyy0810/221494376698)
  
  * 14:22
  
    * `sudo systemctl start elasticsearch.service`가 실행되지 않는 이유
  
    * ```
      Job for elasticsearch.service failed because the control process exited with error code.
      See "systemctl status elasticsearch.service" and "journalctl -xe" for details.
      ```
  
    * `sudo vim /etc/elasticsearch/elasticsearch.yml`을 치고 들어가서
  
    * 다음과 같은 형태로 작성 후 다시 시도
  
      ![image](https://user-images.githubusercontent.com/75322297/165025584-ac4f4ffa-f59d-45f2-b97e-2e4edba251a0.png)
  
    * `curl localhost:9200`으로 상태 확인
  
    * ![image](https://user-images.githubusercontent.com/75322297/165026319-332d9c5c-e547-47bd-9138-d6bf41158116.png)
  
  * 14:34
  
    * 한글 형태소 분석기 **노리(nori)** 설치
      * `sudo /usr/share/elasticsearch/bin/elasticsearch-plugin install analysis-nori`
  
  * 14:49
  
    * seoul.csv 우분투로 이동
  
    * start_app  어플리케이션의 `models.py`의 내용
  
      * 따라하기 단계여서 타입을 모두 텍스트 형태로 지정
  
      ![image](https://user-images.githubusercontent.com/75322297/165028411-0e2bd087-bf15-4dad-82fc-522acc92aed2.png)
  
    * 구성
  
      * id
      * s_name
      * s_add
      * s_road
      * s_kind
      * lat
      * lot
      * s_status
  
  * 14:57
  
    * 노리(nori) 토크나이저(tokenizer)란?
      * [https://esbook.kimjmin.net/06-text-analysis/6.7-stemming/6.7.2-nori](https://esbook.kimjmin.net/06-text-analysis/6.7-stemming/6.7.2-nori)
      * 프랑스 개발자가 한국어분석기를 만들어?..
      * 단어와 조사의 분리가 가능한 아주 유용한 ..
  
  * 15:08
  
    * `documents.py` 작성
  
      ```
      from elasticsearch_dsl import analyzer
      from django_elasticsearch_dsl import DocType, Index, fields
      
      
      from .models import Restaurants
      
      
      stores = Index('search_app_stores')
      stores.settings(
              number_of_shards=1,
              number_of_replicas=0
      )
      
      
      nori_korean = analyzer(
              'nori_korean',
              tokenizer = "nori_tokenizer",
              filter=["lowercase", "stop"],
      )
      
      
      class StoresDocument(DocType):
          s_name = fields.TextField(
                  analyzer=nori_korean,
                  fields={'raw': fields.KeywordField()}
          )
          s_kind = fields.TextField(
                  analyzer=keyword,
                  fields={'raw': fields.KeywordField()}
      
          )
      
          class Meta:
              model = Stores
              index = 'search_app_stores'
              fields = [
                      's_id',
                      's_add',
                      's_road',
                      'lat',
                      'lot',
                      's_status',
              ]
                                      
      
      ```
  
  * 16:05
  
    * 서울시 음식점 데이터 `id 7643`번 종로 **N/A**를 이상하게 인식해서 크롤링 멈춤. <- 고쳐야할 사항임
  
  * 16:07
  
    * `django.utils.encoding` -> `six`
  
      ![image](https://user-images.githubusercontent.com/75322297/165037935-eef07411-e950-4ee8-bf4d-d3feca30c017.png)
  
  * 21:55
  
    * 다시 과정을 처음부터 차근차근해봐야겠다.